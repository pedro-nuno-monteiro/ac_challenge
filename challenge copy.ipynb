{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Import de todas as bibliotecas necessárias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Leitura do local dataframe + infos básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('RTA Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()   #verificar quantas colunas têm valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Analisar e eliminar colunas não importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte, analisamos o que significam algumas colunas que aparentam não ser tão importantes para a nossa análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise, eliminamos as colunas que afetam pouco a nossa saída, que, como sabemos, é a última coluna: \"Gravidade do Acidente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_a_eliminar = ['Type_of_vehicle', 'Owner_of_vehicle', 'Defect_of_vehicle', 'Area_accident_occured',\n",
    "                     'Pedestrian_movement', 'Fitness_of_casuality', 'Work_of_casuality', 'Time', 'Day_of_week']\n",
    "\n",
    "df.drop(colunas_a_eliminar, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para uma melhor compreensão da tabela, vamos renomear as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time, day_of_week, age_band_of_driver, sex_of_driver, educational_level, vehicle_driver_relation, driving_experience\n",
    "#type_of_vehicle, owner_of_vehicle, service_year_of_vehicle, defect_of_vehicle, area_accident_occured\n",
    "#lanes_or_medians, road_allignment, types_of_junction, road_surface_type, road_surface_conditions, ligh_conditions\n",
    "#weather_conditions, type_of_collision, number_of_vehicles_involved, number_of_casualties, vehicle_movement\n",
    "#casualty_class, sex_of_casualty, age_band_of_casualty, casualty_severity, work_of_casualty, fitness_of_casualty\n",
    "#pedestrian_movement, cause_of_accident, accident_severity,\n",
    "colunas_renomeadas = ['Faixa Etária', 'Género', 'Nível de Educação', 'Relação com o Veículo', \n",
    "                      'Experiência de Condução', 'Idade do Veículo', 'Situação de Faixa', 'Alinhamento da Estrada', 'Tipo de Cruzamento',\n",
    "                      'Tipo de Estrada', 'Condições do Piso', 'Condições de Visibilidade',\n",
    "                      'Condiçoes Meteorológicas', 'Tipo de Colisão', 'N.º Veículos Envolvidos',\n",
    "                      'Número de Vítimas', 'Movimento do Veículo', 'Tipo de Vítima','Género da Vítima',\n",
    "                      'Faixa Etária da Vítima', 'Gravidade da Vítima',\n",
    "                      'Causa do Acidente', 'Gravidade do Acidente']\n",
    "\n",
    "df.columns = colunas_renomeadas\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Análise e substituição de valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte, substituímos os valores escritos \"na\" por um valor verdadeirmente nulo, \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('na', pd.NA, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui percebemos a proporção de cada valor em cada coluna, incluindo os valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_values = {}\n",
    "for column in df.columns:\n",
    "    counts = df[column].value_counts(normalize=True, dropna=False) * 100\n",
    "    percentage_values[column] = counts\n",
    "\n",
    "for column, percentages in percentage_values.items():\n",
    "    print(percentages)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ainda realizar a substituição de valores nulos pela moda da coluna.\n",
    "\n",
    "Neste passo, fomos apenar substituir os valores nulos cujas colunas tinham menos de 1000 valores \"NaN\", uma vez que afeta pouco a proporção dos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Nível de Educação'] = df['Nível de Educação'].fillna(df['Nível de Educação'].mode()[0])\n",
    "df['Relação com o Veículo'] = df['Relação com o Veículo'].fillna(df['Relação com o Veículo'].mode()[0])\n",
    "df['Experiência de Condução'] = df['Experiência de Condução'].fillna(df['Experiência de Condução'].mode()[0])\n",
    "df['Situação de Faixa'] = df['Situação de Faixa'].fillna(df['Situação de Faixa'].mode()[0])\n",
    "df['Tipo de Cruzamento'] = df['Tipo de Cruzamento'].fillna(df['Tipo de Cruzamento'].mode()[0])\n",
    "df['Tipo de Estrada'] = df['Tipo de Estrada'].fillna(df['Tipo de Estrada'].mode()[0])\n",
    "df['Tipo de Colisão'] = df['Tipo de Colisão'].fillna(df['Tipo de Colisão'].mode()[0])\n",
    "df['Movimento do Veículo'] = df['Movimento do Veículo'].fillna(df['Movimento do Veículo'].mode()[0])\n",
    "\n",
    "#substituir por valores em que a coluna da gravidade é a mesma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()   #verificar quantas colunas têm valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proporções novas de todas as colunas\n",
    "percentage_values = {}\n",
    "for column in df.columns:\n",
    "    counts = df[column].value_counts(normalize=True, dropna=False) * 100\n",
    "    percentage_values[column] = counts\n",
    "\n",
    "for column, percentages in percentage_values.items():\n",
    "    print(percentages)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELIMINAR AS COLUNAS 4000 E TRAZER ALGUMAS DE VOLTA QUE ELIMINÁMOS MAIS CEDO\n",
    "\n",
    "# várias experiências (exp1 - manter proporção, exp2 - subs pela moda, exp3 - fazer o KNN, exp4 - eliminar colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar as 4 colunas com mais de 1000 valores \"NA\", temos 2 soluções: ou eliminamos as colunas, ou repartimos a sua proporção pelos restantes valores da coluna.\n",
    "\n",
    "Eliminar uma coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_a_eliminar_2 = ['Género da Vítima']\n",
    "df.drop(colunas_a_eliminar_2, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartir a proporção pelos restantes valores das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to process\n",
    "columns_to_process = ['Gravidade da Vítima', 'Faixa Etária da Vítima', 'Ocupação da Vítima']\n",
    "\n",
    "for column in columns_to_process:\n",
    "    # Number of null values in the column\n",
    "    null_count = df[column].isnull().sum()\n",
    "\n",
    "    # Proportion of non-null values for each category\n",
    "    category_proportions = df[column].value_counts(normalize=True)\n",
    "\n",
    "    # Calculate the number of null values to be distributed for each category\n",
    "    null_distribution = (category_proportions * null_count).round().astype(int)\n",
    "\n",
    "    # Randomly assign the null values to each category\n",
    "    null_indices = df[df[column].isnull()].index\n",
    "    for category, count in null_distribution.items():\n",
    "        sample_indices = np.random.choice(null_indices, size=count, replace=False)\n",
    "        df.loc[sample_indices, column] = category\n",
    "\n",
    "    # Fill any remaining null values randomly\n",
    "    remaining_null_indices = df[df[column].isnull()].index\n",
    "    remaining_categories = list(category_proportions.index)\n",
    "    for index in remaining_null_indices:\n",
    "        df.at[index, column] = np.random.choice(remaining_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num ponto à parte, percebemos que eliminar as linhas com valores nulos não é uma opção, uma vez que perderíamos metade dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_linhas_na = df.isna().any(axis=1).sum()\n",
    "\n",
    "print(\"Total de linhas com valores NaN\", no_linhas_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Fazer matriz de correlação e importância de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos analisar a matriz de correlação entre as várias variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()  # aplicar Label Encoder a todas as colunas \"object\"\n",
    "for column in df.select_dtypes(include = 'object').columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize = (20, 15))\n",
    "sns.heatmap(correlation_matrix, annot = True, cmap = 'vlag', fmt = \".2f\", linewidths = 1, square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[['Gravidade da Vítima', 'Gravidade do Acidente']]\n",
    "correlation_matrix = df_2.corr()\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.heatmap(correlation_matrix, annot = True, cmap = 'vlag', fmt = \".4f\", linewidths = 1, square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df['Gravidade do Acidente'], df['Gravidade da Vítima'], normalize='index') * 100\n",
    "\n",
    "# Display the proportions\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, analisamos a importância de cada feature para o modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values # todas as features\n",
    "Y =  df.iloc[:, -1].values # feature target\n",
    "\n",
    "modelo = ExtraTreesClassifier()\n",
    "modelo.fit(X, Y)\n",
    "\n",
    "feature_importances = pd.Series(modelo.feature_importances_, index = df.columns[:-1])\n",
    "feature_importances.nlargest(10).plot(kind='barh')  # mostrar as 10 features mais importantes\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste ponto, dividimos os dados em sets de treino e de teste, utilizando 25% dos dados para teste e os restantes para teino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 30)\n",
    "\n",
    "print(\"Número de exemplos nos dados de treino: \", X_train.shape[0])\n",
    "print(\"Número de exemplos nos dados de teste: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 6 - Árvores de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro modelo de machine learning utilizado foi o modelo de árvores de decisão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos estanderizar as nossas features. Isso é feito para garantir que todas as características tenham a mesma escala, o que pode melhorar o desempenho do algoritmo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parâmetro max_depth = 4 define a profundidade máxima da árvore de decisão, \n",
    "# visto que limitar a profundidade pode ajudar a evitar overfitting, tornando a árvore mais simples.\n",
    "clf = DecisionTreeClassifier(random_state = 42, criterion = \"entropy\", max_depth = 4)\n",
    "\n",
    "# Treino: Arvore de Decisão\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Previsão da resposta --> Teste\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# Print dos valores accuracy\n",
    "print('Train data accuracy: ', accuracy_score(y_true = y_train, y_pred = y_train_pred))\n",
    "print('Test data accuracy: ', accuracy_score(y_true = y_test, y_pred = y_test_pred))\n",
    "print('Decision tree accuracy: ', accuracy_score(y_test_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "tree.plot_tree(clf, fontsize = 8, feature_names = df.columns[:-1], filled = True, rounded = True, proportion=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Através do classification report, podemos concluir a acurácia do modelo tal como o recall, a precisão e o f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_pred, zero_division = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após realizar um classification report, vamos agora mostrar a matriz de confusão. Assim podemos ver a quantidade de falsos positivos e falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot = True, cmap = 'seismic', fmt = \"4.0f\")\n",
    "ax.set_title('Seaborn Confusion Matrix\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted decision case disposition')\n",
    "ax.set_ylabel('Actual decision case disposition ')\n",
    "\n",
    "print(cf_matrix)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
